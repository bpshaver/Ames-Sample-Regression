{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train.csv'\n",
    "kaggl_dir  = 'data/test.csv'\n",
    "# submission_path = 'data/test_submission.csv'\n",
    "submission_path = None\n",
    "brute = False\n",
    "interaction_only = True\n",
    "run_lin = True\n",
    "run_ridge = True\n",
    "run_las = True\n",
    "run_elnet = True\n",
    "\n",
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "# Additional Imports:\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, Lasso, ElasticNetCV\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "train_data = pd.read_csv(train_dir, index_col = 'Id')\n",
    "kaggl_data = pd.read_csv(kaggl_dir,  index_col = 'Id')\n",
    "\n",
    "# Train/Test Split\n",
    "\n",
    "X = train_data.drop('SalePrice', axis=1)\n",
    "y = train_data['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "print('Training data has {} rows.'.format(X_train.shape[0]))\n",
    "print('Testing data has {} rows.'.format(X_test.shape[0]))\n",
    "print('Kaggle data has {} rows.'.format(kaggl_data.shape[0]))\n",
    "\n",
    "# Manual Feature Engineering\n",
    "print('Manual Feature Engineering...')\n",
    "\n",
    "# Create an 'EDA' dataframe we'll use to do some exploring\n",
    "EDA = X_train.copy()\n",
    "EDA['SalePrice'] = y_train\n",
    "\n",
    "# There are 27 neighborhoods. Let's put them into groups of 9:\n",
    "neighborhood_ranks = EDA.groupby('Neighborhood')['SalePrice'].mean().sort_values().index\n",
    "\n",
    "low_neigh  = neighborhood_ranks[:9]\n",
    "mid_neigh  = neighborhood_ranks[9:18]\n",
    "high_neigh = neighborhood_ranks[18:]\n",
    "\n",
    "def manual_feature_eng(data):\n",
    "    '''Some basic manual feature engineering based on EDA of X_train'''\n",
    "    eng_data = data.copy()\n",
    "    # Years info:\n",
    "    eng_data['Years_Old'] = 2018 - eng_data['Year Built']\n",
    "    eng_data['Garage Age'] = 2018 - eng_data['Garage Yr Blt']\n",
    "    eng_data['Years Since Sale'] = 2018 - eng_data['Yr Sold']\n",
    "    eng_data['Years Since Remodel'] = 2018 - eng_data['Year Remod/Add']\n",
    "    eng_data.drop(['Year Built','Garage Yr Blt','Yr Sold','Year Remod/Add'],\n",
    "                 axis=1, inplace=True)\n",
    "    # Neighborhood info:\n",
    "    eng_data['High_Neigh'] = [1 if x in high_neigh else 0 for x in eng_data['Neighborhood']]\n",
    "    eng_data['Mid_Neigh'] = [1 if x in mid_neigh else 0 for x in eng_data['Neighborhood']]\n",
    "    eng_data['Low_Neigh'] = [1 if x in low_neigh else 0 for x in eng_data['Neighborhood']]\n",
    "    eng_data.drop('Neighborhood', axis=1, inplace=True)\n",
    "    \n",
    "    # Is there miscellaneous furniture?\n",
    "    eng_data['MiscFurn'] = eng_data['Misc Val'] > 0\n",
    "    return eng_data\n",
    "\n",
    "X_train = manual_feature_eng(X_train)\n",
    "X_test = manual_feature_eng(X_test)\n",
    "kaggl_data = manual_feature_eng(kaggl_data)\n",
    "\n",
    "# Data Preprocessing: Categorical Data\n",
    "print('Processing Categorical Data...')\n",
    "\n",
    "# Before we begin, let's check to see if there are any columns in the Kaggle \n",
    "# set that aren't in the training set:\n",
    "\n",
    "assert [col for col in kaggl_data.columns if col not in X_train.columns] == []\n",
    "\n",
    "# And vice versa:\n",
    "\n",
    "assert [col for col in X_train.columns if col not in kaggl_data.columns] == []\n",
    "\n",
    "# All of our preprocessing will ultimately go here:\n",
    "def preprocessing(data):\n",
    "    try:\n",
    "        cleaned_data = data.drop('PID', axis=1)\n",
    "    except:\n",
    "        cleaned_data = data\n",
    "    fillna_dict = {\n",
    "        'Pool QC':'No Pool',\n",
    "        'Alley':'No Alley',\n",
    "        # Let's let the get_dummies drop 'Misc Features' if NA\n",
    "        'Fence':'No Fence',\n",
    "        'Fireplace Qu':'No Fireplace',\n",
    "        # Lot frontage can be mean imputed\n",
    "        'Garaga Finish': 'No Garage',\n",
    "        'Garage Qual': 'No Garage',\n",
    "        'Garage Cond': 'No Garage',\n",
    "        'Garage Type': 'No Garage',\n",
    "        'Bsmt Exposure':'No Garage',\n",
    "        'BsmtFin Type 2':'No Basement',\n",
    "        'BsmtFin Type 2':'No Basement',\n",
    "        'BsmtFin Type 1':'No Basement',\n",
    "        'Bsmt Cond':'No Basement',\n",
    "        'Bsmt Qual':'No Basement',\n",
    "        'Mas Vnr Type':'No Mas Vnr'        \n",
    "    }\n",
    "    \n",
    "    cleaned_data = cleaned_data.fillna(fillna_dict)\n",
    "    \n",
    "    return(cleaned_data)\n",
    "    \n",
    "X_train = preprocessing(X_train)\n",
    "X_test  = preprocessing(X_test)\n",
    "kaggl_data = preprocessing(kaggl_data)\n",
    "\n",
    "# Grab the string columns:\n",
    "string_cols = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Get some dummies:\n",
    "X_train = pd.get_dummies(X_train, columns=string_cols)\n",
    "X_test = pd.get_dummies(X_test, columns=string_cols)\n",
    "kaggl_data = pd.get_dummies(kaggl_data, columns=string_cols)\n",
    "\n",
    "# Addressing Column Mismatch After Dummifying\n",
    "print('Addressing column mismatch...')\n",
    "\n",
    "# Add columns of zeros to test and kaggle sets for columns that *do* appear in\n",
    "# the training set.\n",
    "\n",
    "model_cols = X_train.columns\n",
    "\n",
    "def add_model_cols(data, model_cols):\n",
    "    new_data = data.copy()\n",
    "    for missing_col in [col for col in model_cols if col not in data.columns]:\n",
    "        new_data[missing_col] = 0\n",
    "    return new_data\n",
    "\n",
    "X_test = add_model_cols(X_test, model_cols=model_cols)\n",
    "kaggl_data = add_model_cols(kaggl_data, model_cols=model_cols)\n",
    "\n",
    "# Now, let's only consider columns in X_test and kaggl_data that appear in\n",
    "# the training set. We'll call these 'model columns':\n",
    "\n",
    "kaggl_data = kaggl_data[model_cols]\n",
    "X_test     = X_test[model_cols]\n",
    "\n",
    "# Make sure we've done this correctly:\n",
    "assert X_train.shape[1] == X_test.shape[1] == kaggl_data.shape[1]\n",
    "assert X_train.columns.all() == X_test.columns.all()== kaggl_data.columns.all() \n",
    "\n",
    "# Imputing Numerical Missing Data: Handling Numerical Data\n",
    "print('Imputing missing numerical data...')\n",
    "\n",
    "imp = Imputer(strategy='mean')\n",
    "imp.fit(X_train)\n",
    "X_train = imp.transform(X_train)\n",
    "X_test  = imp.transform(X_test)\n",
    "kaggl_data = imp.transform(kaggl_data)\n",
    "\n",
    "def array_null_check(array):\n",
    "    '''Turns an array into a dataframe so that we can check for null values'''\n",
    "    return pd.DataFrame(array).isnull().sum().sum()\n",
    "\n",
    "assert array_null_check(X_train) == array_null_check(X_test) \\\n",
    "                                 == array_null_check(kaggl_data)\n",
    "\n",
    "# Brute Force Feature Engineering\n",
    "\n",
    "if brute:\n",
    "    print('Brute force feature engineering...')\n",
    "    pf = PolynomialFeatures(interaction_only=interaction_only)\n",
    "    X_train = pf.fit_transform(X_train)\n",
    "    X_test  = pf.transform(X_test)\n",
    "    kaggl_data = pf.transform(kaggl_data)\n",
    "\n",
    "# Maybe this is too many columns???\n",
    "print('X_train has:\\n---{} rows\\n---{} columns'.format(X_train.shape[0], X_train.shape[1]))\n",
    "\n",
    "# Scaling\n",
    "print('Scaling all columns...')\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test  = ss.transform(X_test)\n",
    "kaggl_data = ss.transform(kaggl_data)\n",
    "\n",
    "# Feature Elimination\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectPercentile, f_regression\n",
    "\n",
    "if brute:\n",
    "    print('Performing automatic feature elimination')\n",
    "    # Only do feature elimination if feature engineering happened by brute force\n",
    "    feature_variances = np.apply_along_axis(np.var, axis=0, arr= X_train)\n",
    "\n",
    "    # Define a percentile threshold. Do I want the top 1% of features by variance?\n",
    "    perc_thresh = np.percentile(feature_variances, 99)\n",
    "    perc_thresh\n",
    "\n",
    "    vt = VarianceThreshold(threshold=perc_thresh)\n",
    "    X_train_reduced = vt.fit_transform(X_train)\n",
    "    X_test_reduced  = vt.transform(X_test)\n",
    "    kaggl_reduced   = vt.transform(kaggl_data)\n",
    "    print('X_train now has:\\n---{} rows\\n---{} columns'.format(X_train.shape[0], X_train.shape[1]))\n",
    "else:\n",
    "    X_train_reduced = X_train\n",
    "    X_test_reduced  = X_test\n",
    "    kaggl_reduced   = kaggl_data\n",
    "\n",
    "# Or do I want to select the top 1% of features according \n",
    "# to the f_regression function?\n",
    "\n",
    "# sp = SelectPercentile(score_func=f_regression, percentile = 1)\n",
    "# X_train_reduced = sp.fit_transform(X_train, y_train)\n",
    "# X_test_reduced  = sp.transform(X_test)\n",
    "# kaggl_reduced   = sp.transform(kaggl_data)\n",
    "# print(X_train.shape[1])\n",
    "\n",
    "## Modeling\n",
    "\n",
    "# Linear Regression\n",
    "\n",
    "if run_lin:\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(X_train_reduced, y_train)\n",
    "    cv_scores = cross_val_score(lin, X_train_reduced, y_train, cv=3).mean()\n",
    "\n",
    "    print('{} model has average performance of {}'\n",
    "          .format(str(lin).split('(')[0], cv_scores.mean()))\n",
    "\n",
    "# Ridge Regression\n",
    "\n",
    "if run_ridge:\n",
    "    rid = RidgeCV()\n",
    "    rid.fit(X_train_reduced, y_train)\n",
    "    cv_scores = cross_val_score(rid, X_train_reduced, y_train, cv=3).mean()\n",
    "\n",
    "    print('{} model has average performance of {}'\n",
    "          .format(str(rid).split('(')[0], cv_scores.mean()))\n",
    "\n",
    "# Lasso Regression\n",
    "\n",
    "if run_las:\n",
    "    # Define a reasonable range of alphas based on previous LASSO fits:\n",
    "    alphas = np.logspace(2,4,20)\n",
    "    las = LassoCV(alphas=alphas, n_jobs=-1)\n",
    "    las.fit(X_train_reduced, y_train)\n",
    "    cv_scores = cross_val_score(las, X_train_reduced, y_train, cv=3).mean()\n",
    "    best_alpha = las.alpha_\n",
    "    print('{} model has average performance of {}'\n",
    "          .format(str(las).split('(')[0], cv_scores.mean()))\n",
    "\n",
    "las = Lasso(alpha=best_alpha, max_iter=2000)\n",
    "cv_scores = cross_val_score(las, X_train_reduced, y_train, cv=3).mean()\n",
    "las.fit(X_train_reduced, y_train)\n",
    "print('{} model has average performance of {}'\n",
    "      .format(str(las).split('(')[0], cv_scores.mean()))\n",
    "\n",
    "# ElasticNet Regression\n",
    "\n",
    "if run_elnet:\n",
    "    elnet = ElasticNetCV(n_alphas=10)\n",
    "    elnet.fit(X_train_reduced, y_train)\n",
    "    cv_scores = cross_val_score(elnet, X_train_reduced, y_train, cv=3).mean()\n",
    "\n",
    "    print('{} model has average performance of {}'\n",
    "          .format(str(elnet).split('(')[0], cv_scores.mean()))\n",
    "\n",
    "# Final Model Test\n",
    "\n",
    "models = {}\n",
    "\n",
    "try:\n",
    "    lin_score = lin.score(X_test_reduced, y_test)\n",
    "    models[lin_score] = lin\n",
    "    print('Test set performance of {}: {}'.format(str(lin).split('(')[0],lin_score))\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "try:\n",
    "    rid_score = rid.score(X_test_reduced, y_test)\n",
    "    models[rid_score] = rid\n",
    "    print('Test set performance of {}: {}'.format(str(rid).split('(')[0],rid_score))\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "try:\n",
    "    las_score = las.score(X_test_reduced, y_test)\n",
    "    models[las_score] = las\n",
    "    print('Test set performance of {}: {}'.format(str(las).split('(')[0],las_score))\n",
    "except:\n",
    "    pass          \n",
    "\n",
    "try:\n",
    "    elnet_score = elnet.score(X_test_reduced, y_test)\n",
    "    models[elnet_score] = elnet\n",
    "    print('Test set performance of {}: {}'.format(str(elnet).split('(')[0],elnet_score))\n",
    "except:\n",
    "    pass   \n",
    "\n",
    "high_score = max(models.keys())\n",
    "print('Best performing model was {},\\nwith test set performance of {}'.format(\n",
    "    str(models[high_score]).split('(')[0], round(high_score,5)))\n",
    "\n",
    "# Choosing a Model and Outputting Submission:\n",
    "\n",
    "# Choose a model based on test set performance:\n",
    "chosen_model = models[high_score]\n",
    "\n",
    "if submission_path:\n",
    "\n",
    "    kaggl_preds = chosen_model.predict(kaggl_reduced)\n",
    "\n",
    "    kaggl_id = pd.read_csv('data/test.csv')['Id']\n",
    "\n",
    "    sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "    submission_columns= sample_submission.columns\n",
    "\n",
    "    submission = pd.DataFrame({submission_columns[0]:kaggl_id,\n",
    "                               submission_columns[1]:kaggl_preds})\n",
    "\n",
    "    submission.to_csv(submission_path, index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
